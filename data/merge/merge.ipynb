{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_uri</th>\n",
       "      <th>agent_label</th>\n",
       "      <th>work_uri</th>\n",
       "      <th>work_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://pikecooper/005bc095-ffc1-41d3-9afa-e81...</td>\n",
       "      <td>Dick Ross</td>\n",
       "      <td>https://pikecooper/e5e2bc2d-239f-4871-8f13-fd8...</td>\n",
       "      <td>Shadow of the Boomerang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://pikecooper/02045c46-2cb9-45ae-ab7e-4ca...</td>\n",
       "      <td>George Dean</td>\n",
       "      <td>https://pikecooper/7bdc0f62-cfd3-497d-94bb-4a3...</td>\n",
       "      <td>A Long, Long Way to Tipperary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://pikecooper/046937df-0b34-41f9-b6c3-f41...</td>\n",
       "      <td>Lee Robinson</td>\n",
       "      <td>https://pikecooper/27f0b2f2-c6bd-4aaf-b64e-6fe...</td>\n",
       "      <td>The Phantom Stockman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pikecooper/046937df-0b34-41f9-b6c3-f41...</td>\n",
       "      <td>Lee Robinson</td>\n",
       "      <td>https://pikecooper/6f0567f2-16e7-4ea9-a651-15f...</td>\n",
       "      <td>King of the Coral Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://pikecooper/046937df-0b34-41f9-b6c3-f41...</td>\n",
       "      <td>Lee Robinson</td>\n",
       "      <td>https://pikecooper/817a62a8-9a47-4516-abcb-59f...</td>\n",
       "      <td>The Intruders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           agent_uri   agent_label  \\\n",
       "0  https://pikecooper/005bc095-ffc1-41d3-9afa-e81...     Dick Ross   \n",
       "1  https://pikecooper/02045c46-2cb9-45ae-ab7e-4ca...   George Dean   \n",
       "2  https://pikecooper/046937df-0b34-41f9-b6c3-f41...  Lee Robinson   \n",
       "3  https://pikecooper/046937df-0b34-41f9-b6c3-f41...  Lee Robinson   \n",
       "4  https://pikecooper/046937df-0b34-41f9-b6c3-f41...  Lee Robinson   \n",
       "\n",
       "                                            work_uri  \\\n",
       "0  https://pikecooper/e5e2bc2d-239f-4871-8f13-fd8...   \n",
       "1  https://pikecooper/7bdc0f62-cfd3-497d-94bb-4a3...   \n",
       "2  https://pikecooper/27f0b2f2-c6bd-4aaf-b64e-6fe...   \n",
       "3  https://pikecooper/6f0567f2-16e7-4ea9-a651-15f...   \n",
       "4  https://pikecooper/817a62a8-9a47-4516-abcb-59f...   \n",
       "\n",
       "                      work_label  \n",
       "0        Shadow of the Boomerang  \n",
       "1  A Long, Long Way to Tipperary  \n",
       "2           The Phantom Stockman  \n",
       "3          King of the Coral Sea  \n",
       "4                  The Intruders  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine datasets.\n",
    "\n",
    "from thefuzz import process\n",
    "from thefuzz import fuzz\n",
    "import numpy\n",
    "import pandas\n",
    "import pathlib\n",
    "import pydash\n",
    "import rdflib\n",
    "import tqdm\n",
    "import uuid\n",
    "\n",
    "def print_label(a, g):\n",
    "\n",
    "    ''' Lookup a label for an entity. '''\n",
    "\n",
    "    a_label = [o for s,p,o in g.triples((a, rdflib.RDFS.label, None))]\n",
    "    return str(a_label[0])\n",
    "\n",
    "def graph_to_dataframe(g, title_predicate):\n",
    "\n",
    "    ''' Build agent and work dataframe out of a graph. '''\n",
    "\n",
    "    df = pandas.DataFrame(columns=['agent_uri', 'agent_label'])\n",
    "    for a, b, c in g.triples((None, None, ont.Person)):\n",
    "        for d, e ,f in g.triples((a, rdflib.RDFS.label, None)):\n",
    "            df.loc[len(df)] = [(a), (f)]\n",
    "\n",
    "    activity = pandas.DataFrame()\n",
    "    for x in [ont.hasActor, ont.hasDirector, ont.hasProducer]:\n",
    "        connection = pandas.DataFrame(columns=['agent_uri', 'work_uri'])\n",
    "        for a, b, c in g.triples((None, x, None)):\n",
    "            connection.loc[len(connection)] = [(c), (a)]\n",
    "        activity = pandas.concat([activity, connection])\n",
    "    df = pandas.merge(df, activity, on='agent_uri', how='left')\n",
    "\n",
    "    title = pandas.DataFrame(columns=['work_uri', 'work_label'])\n",
    "    for a, b, c in g.triples((None, None, ont.Work)):\n",
    "        for d, e ,f in g.triples((a, title_predicate, None)):\n",
    "            title.loc[len(title)] = [(a), (f)]\n",
    "    df = pandas.merge(df, title, on='work_uri', how='left')\n",
    "\n",
    "    return df\n",
    "\n",
    "def merge_entities(match_df, g):\n",
    "\n",
    "    ''' Create new graph with merged nodes. '''\n",
    "\n",
    "    matched_uri = pydash.uniq(list(match_df.a.unique())+list(match_df.b.unique()))\n",
    "    merge_instances = dict()\n",
    "    for x in matched_uri:\n",
    "        family = match_df.loc[match_df.a.isin([x]) | match_df.b.isin([x])]\n",
    "        if len(family):\n",
    "            family_members = pydash.uniq(list(family.a.unique())+list(family.b.unique()))\n",
    "            merge_uri = rdflib.URIRef(f'https://merge/{str(uuid.uuid4())}')\n",
    "            for f in family_members:\n",
    "                merge_instances[f] = merge_uri\n",
    "\n",
    "            match_df = match_df.loc[~match_df.a.isin(family_members)]\n",
    "            match_df = match_df.loc[~match_df.b.isin(family_members)]\n",
    "\n",
    "    n_graph = rdflib.Graph()\n",
    "    for s,p,o in g.triples((None, None, None)):\n",
    "        if s in merge_instances.keys():\n",
    "            s = merge_instances[s]\n",
    "        if o in merge_instances.keys():\n",
    "            o = merge_instances[o]\n",
    "        n_graph.add((s,p,o))\n",
    "\n",
    "    return n_graph\n",
    "\n",
    "graph = rdflib.Graph()\n",
    "ont = rdflib.Namespace(\"https://australian-filmography.wiki/ontology/\")\n",
    "\n",
    "graph.parse(pathlib.Path.cwd().parents[0] / 'source' / 'pike-cooper' / 'pike-cooper.ttl')\n",
    "graph.parse(pathlib.Path.cwd().parents[0] / 'source' / 'ozmovies' / 'ozmovies.ttl')\n",
    "\n",
    "dataframe = graph_to_dataframe(graph, ont.hasTitle)\n",
    "\n",
    "print(len(dataframe))\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7262/7262 [09:05<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37683\n"
     ]
    }
   ],
   "source": [
    "# agent matching.\n",
    "\n",
    "sample = dataframe.copy()\n",
    "\n",
    "match_dataframe = pandas.DataFrame(columns=['a', 'a_label', 'b', 'b_label'])\n",
    "for sub in tqdm.tqdm(sample.agent_uri.unique()):\n",
    "    sub_filmography = sample.loc[sample.agent_uri.isin([sub])].to_dict('records')\n",
    "    sub_labels = pydash.uniq([str(x['agent_label']) for x in sub_filmography])\n",
    "    label_match = pydash.flatten([(process.extract(x, sample.agent_label.unique(), limit=1000, scorer=fuzz.token_sort_ratio)) for x in sub_labels])\n",
    "    label_match = [x[0] for x in label_match if x[1] > 70]\n",
    "\n",
    "    candidates = sample.loc[sample.agent_label.isin(label_match)]\n",
    "    for can in candidates.agent_uri.unique():\n",
    "        if can != sub: # note you could also force distinctions here!\n",
    "            can_filmography = sample.loc[sample.agent_uri.isin([can])].to_dict('records')\n",
    "            if len(sub_filmography) >= 1 and len(can_filmography) >= 1: # higher numbers return fewer, more confident matches.\n",
    "                \n",
    "                can_score = list()\n",
    "                for f in sub_filmography:\n",
    "                    match = process.extractOne(str(f['work_label']), list([x['work_label'] for x in can_filmography]), scorer=fuzz.token_sort_ratio)\n",
    "                    can_score.append(match[1])\n",
    "\n",
    "                if numpy.median(can_score) == 100:\n",
    "                    match_dataframe.loc[len(match_dataframe)] = [(can), (print_label(can, graph)), (sub), (print_label(sub, graph))] \n",
    "\n",
    "graph = merge_entities(match_dataframe, graph)\n",
    "print(len(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36760\n"
     ]
    }
   ],
   "source": [
    "# exact title match.\n",
    "\n",
    "dataframe = graph_to_dataframe(graph, rdflib.RDFS.label)\n",
    "overlap = dataframe.copy().drop_duplicates()\n",
    "overlap = overlap[['agent_uri',  'work_label']]\n",
    "overlap = overlap[overlap.duplicated(keep=False)].drop_duplicates()\n",
    "\n",
    "match_dataframe = pandas.DataFrame(columns=['a', 'b'])\n",
    "for o in overlap.to_dict('records'):\n",
    "    block = dataframe.copy()\n",
    "    block = block.loc[block.agent_uri.isin([o['agent_uri']])]\n",
    "    block = block.loc[block.work_label.isin([o['work_label']])]\n",
    "    same_values = list(block.work_uri.unique())\n",
    "    for a in same_values[1:]:\n",
    "        match_dataframe.loc[len(match_dataframe)] = [(same_values[0]), (a)]\n",
    "\n",
    "graph = merge_entities(match_dataframe, graph)\n",
    "print(len(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36757\n"
     ]
    }
   ],
   "source": [
    "# exact agent match.\n",
    "\n",
    "dataframe = graph_to_dataframe(graph, rdflib.RDFS.label)\n",
    "overlap = dataframe.copy().drop_duplicates()\n",
    "overlap = overlap[['agent_label', 'work_uri']]\n",
    "overlap = overlap[overlap.duplicated(keep=False)].drop_duplicates()\n",
    "\n",
    "match_dataframe = pandas.DataFrame(columns=['a', 'b'])\n",
    "for o in overlap.to_dict('records'):\n",
    "    block = dataframe.copy()\n",
    "    block = block.loc[block.agent_label.isin([o['agent_label']])]\n",
    "    block = block.loc[block.work_uri.isin([o['work_uri']])]\n",
    "    same_values = list(block.agent_uri.unique())\n",
    "    for a in same_values[1:]:\n",
    "        match_dataframe.loc[len(match_dataframe)] = [(same_values[0]), (a)]\n",
    "\n",
    "graph = merge_entities(match_dataframe, graph)\n",
    "print(len(graph)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done.\n"
     ]
    }
   ],
   "source": [
    "graph.serialize(destination=str(pathlib.Path.cwd() / 'merge.ttl'), format=\"turtle\")\n",
    "print('all done.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
